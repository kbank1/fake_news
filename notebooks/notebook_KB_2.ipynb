{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "53a03b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import gensim.downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3a7072",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5810f39",
   "metadata": {},
   "source": [
    "## Main Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7b31650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_target_concat():\n",
    "    \n",
    "    #load data\n",
    "    pol_real=pd.read_json(\"/home/kathrin/code/kbank1/fake_news/raw_data/politifact_hr.json\", orient='index')\n",
    "    pol_fake=pd.read_json(\"/home/kathrin/code/kbank1/fake_news/raw_data/politifact_hf.json\", orient='index')\n",
    "    gossip_fake=pd.read_json(\"/home/kathrin/code/kbank1/fake_news/raw_data/gossipcop_hf.json\", orient='index')\n",
    "    gossip_real=pd.read_json(\"/home/kathrin/code/kbank1/fake_news/raw_data/gossipcop_hr.json\", orient='index')\n",
    "    \n",
    "    #define target\n",
    "    pol_real[\"fake\"]=0\n",
    "    pol_fake[\"fake\"]=1\n",
    "    gossip_real[\"fake\"]=0\n",
    "    gossip_fake[\"fake\"]=1\n",
    "    \n",
    "    #concat\n",
    "    data=pd.concat((pol_fake, pol_real, gossip_fake, gossip_real),axis=0, ignore_index=True)\n",
    "    \n",
    "    print(\"✅ data loaded, target defined, data concatenated\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "20374388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ data loaded, target defined, data concatenated\n"
     ]
    }
   ],
   "source": [
    "data=load_target_concat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620553e0",
   "metadata": {},
   "source": [
    "## Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "50c60c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#politifact=pd.read_json(\"/home/kathrin/code/kbank1/fake_news/raw_data/politifact/politifact_factcheck_data.json\", lines=True)\n",
    "#guardian=pd.read_csv(\"/home/kathrin/code/kbank1/fake_news/raw_data/guardian/the_guardian_full.csv\")\n",
    "#corpus=pd.read_csv(\"/home/kathrin/code/kbank1/fake_news/raw_data/fakenewscorpus/news_1.csv\", nrows=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5907339a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data, filter, roughly cleaned and saved\n",
    "politifact=pd.read_csv(\"/home/kathrin/code/kbank1/fake_news/raw_data/test/politifact_test.csv\")\n",
    "guardian=pd.read_csv(\"/home/kathrin/code/kbank1/fake_news/raw_data/test/guardian_test.csv\")\n",
    "corpus=pd.read_csv(\"/home/kathrin/code/kbank1/fake_news/raw_data/test/corpus_test.csv\")\n",
    "guard_corp=pd.read_csv(\"/home/kathrin/code/kbank1/fake_news/raw_data/test/guard_corp_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4dea2",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fc5abf",
   "metadata": {},
   "source": [
    "## main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6b1daa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates_errors(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean raw data by\n",
    "    - removing duplicates within fake-category (keep 1)\n",
    "    - removing duplicates across fake-categories (delete both)\n",
    "    - deleting texts that are shorter than their title (error messages, headers etc.)\n",
    "    \"\"\"\n",
    "    # Remove duplicates within fake-category\n",
    "    data =data.drop_duplicates(subset=(\"text\", \"fake\"), keep='first', ignore_index=True)\n",
    "\n",
    "    # Remove duplicates across fake-category\n",
    "    data=data.drop_duplicates(subset=(\"text\"), keep=False, ignore_index=True)\n",
    "\n",
    "    # Delete false texts\n",
    "    data[\"text_len\"] = data['text'].str.len()\n",
    "    data[\"title_len\"]=data['title'].str.len()\n",
    "    data=data[data[\"text_len\"]>=data[\"title_len\"]]\n",
    "\n",
    "    print(\"✅ duplicates and errors removed\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6292c3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ duplicates and errors removed\n"
     ]
    }
   ],
   "source": [
    "data=remove_duplicates_errors(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2968ada7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3a1dce17",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#politifact\n",
    "#extract year\n",
    "#politifact['statement_date'] = pd.to_datetime(politifact['statement_date'])\n",
    "#politifact[\"year\"]=politifact[\"statement_date\"].dt.year\n",
    "#select obs after 2019\n",
    "#politifact=politifact[politifact[\"year\"]>2019]\n",
    "#only keep true, false and pants on fire\n",
    "#politifact= politifact[politifact[\"verdict\"].isin([\"false\", \"pants-fire\", \"true\"])]\n",
    "#create variable fake that is 0 if real, 1 if fake\n",
    "#politifact[\"fake\"] = 0  # Default to 0\n",
    "#politifact.loc[politifact[\"verdict\"].isin([\"false\", \"pants-fire\"]), \"fake\"] = 1\n",
    "\n",
    "#politifact[\"text\"]=politifact[\"statement\"]\n",
    "\n",
    "#save\n",
    "#politifact.to_csv(\"/home/kathrin/code/kbank1/fake_news/raw_data/test/politifact_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5a8d4642",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#guardian\n",
    "#guardian= guardian.tail(10000)\n",
    "#guardian=guardian.dropna()\n",
    "#guardian[\"fake\"]=0\n",
    "#guardian[\"text\"]=guardian[\"Content\"]\n",
    "\n",
    "#t1=\"skip past newsletter promotionSign up to The BreakdownFree weekly newsletterThe latest rugby union news and analysis, plus all the week's action reviewed\"\n",
    "#t2=\"Privacy Notice: Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Privacy Policy. We use Google reCaptcha to protect our website and the Google Privacy Policy and Terms of Service apply\"\n",
    "#t3=\"skip past newsletter promotionSign\"\n",
    "#t4=\".after newsletter promotion\"\n",
    "#t5=\"newsletter\"\n",
    "\n",
    "#tlist=[t1, t2, t3, t4, t5]\n",
    "\n",
    "#def clean_guardian(text):\n",
    "#    for t in tlist:\n",
    "#        text = text.replace(t, '')\n",
    "#    return text\n",
    "\n",
    "#guardian[\"text\"]=guardian.text.apply(clean_guardian)\n",
    "\n",
    "#save\n",
    "#guardian.to_csv(\"/home/kathrin/code/kbank1/fake_news/raw_data/test/guardian_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f22d77ca",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#error_count=guardian['text'].str.contains(text).sum()\n",
    "#if error_count>0:\n",
    "#    print (\"There are {m} occurrences\".format(m=error_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e34ef9bd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#corpus\n",
    "#keep only fakes\n",
    "#corpus=corpus[corpus[\"type\"]==\"fake\"]\n",
    "#corpus[\"fake\"]=1\n",
    "#corpus[\"text\"]=corpus[\"content\"]\n",
    "#save\n",
    "#corpus.to_csv(\"/home/kathrin/code/kbank1/fake_news/raw_data/test/corpus_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22ee48b7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#guard_corp\n",
    "#concat\n",
    "#guard_corp= pd.concat((corpus, guardian),axis=0, ignore_index=True)\n",
    "#guard_corp=guard_corp.sample(frac=1).reset_index(drop=True)\n",
    "#save\n",
    "#guard_corp.to_csv(\"/home/kathrin/code/kbank1/fake_news/raw_data/test/guard_corp_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5266b112",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "f0b837e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "\n",
    "    # Removing whitespaces\n",
    "    text = text.strip()\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    # Removing numbers\n",
    "    text = ''.join(char for char in text if not char.isdigit())\n",
    "    # Removing punctuation\n",
    "    #for punctuation in string.punctuation:\n",
    "        #text = text.replace(punctuation, '')\n",
    "    \n",
    "   # symbols=[\"—\", \"“\", \"”\", \"’\", \"‘\"]\n",
    "    #for symbol in symbols:\n",
    "      #  text=text.replace(symbol, '')\n",
    "    \n",
    "    # Tokenizing\n",
    "    tokenized = word_tokenize(text)\n",
    "    \n",
    "    # Removing stopwords\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    without_stopwords = [word for word in tokenized if not word in stop_words]\n",
    "    \n",
    "    cleaned_sentence = \" \".join(without_stopwords)\n",
    "    \n",
    "    return cleaned_sentence\n",
    "    #return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9d7c33ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data.text.apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d7530324",
   "metadata": {},
   "outputs": [],
   "source": [
    "politifact[\"text\"]=politifact.text.apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6f583869",
   "metadata": {},
   "outputs": [],
   "source": [
    "guardian[\"text\"]=guardian.text.apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9290d012",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[\"text\"]=corpus.text.apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "35d833d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "guard_corp[\"text\"]=guard_corp.text.apply(preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2c7635",
   "metadata": {},
   "source": [
    "# Balancing, train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6a72d073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancing(data):\n",
    "    \n",
    "    #split data in true and false and sample\n",
    "    true = data[data['fake'] == 0].sample(n=3500)\n",
    "    #true=pd.read_csv('/home/kathrin/code/kbank1/fake_news/raw_data/sample/sample_true.csv')\n",
    "    \n",
    "    false = data[data['fake'] == 1].sample(n=3500)\n",
    "    #false=pd.read_csv('/home/kathrin/code/kbank1/fake_news/raw_data/sample/sample_false.csv')\n",
    "    \n",
    "    #concat\n",
    "    files = [true, false]\n",
    "    data_concat = pd.concat(files, ignore_index=True)\n",
    "    data_concat.shape\n",
    "    \n",
    "    #define X and Y\n",
    "    X = data_concat['text']\n",
    "    y = data_concat['fake']\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "62dae505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, y= balancing(data)\n",
    "X=pd.read_csv('/home/kathrin/code/kbank1/fake_news/raw_data/sample/X_punc.csv')\n",
    "y=pd.read_csv('/home/kathrin/code/kbank1/fake_news/raw_data/sample/y_punc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "907680b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"text\"]=X.text.apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "bb7e5821",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X[\"text\"]\n",
    "y=y[\"fake\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "c1a1a988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train/test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b8df71",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Test score functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "32086a72",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test_score(pipe, dataset_name):\n",
    "    \"\"\"\n",
    "    input a pipe (preprocessing and modeling)\n",
    "    output a classification report on the test set\n",
    "    \"\"\"\n",
    "    #load data\n",
    "    df=dataset_name\n",
    "    \n",
    "    #apply preprocessing\n",
    "    #df['text'] = df.text.apply(preprocessing)\n",
    "    \n",
    "    #create X and y\n",
    "    X_test_new=df[\"text\"]\n",
    "    y_test_new=df[\"fake\"]\n",
    "    #predict the label\n",
    "    y_pred_new=pipe.predict(X_test_new)\n",
    "    #make a classification report\n",
    "    report=classification_report(y_test_new, y_pred_new, output_dict=True)\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bfed11dd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#create test function for rnn with keras embedding\n",
    "def test_score_RNN(model, dataset_name):\n",
    "    \"\"\"\n",
    "    input a pipe (preprocessing and modeling)\n",
    "    output a classification report on the test set\n",
    "    \"\"\"\n",
    "    \n",
    "    #load data\n",
    "    df=dataset_name\n",
    "    \n",
    "    #apply preprocessing\n",
    "    #df['text'] = df.text.apply(preprocessing)\n",
    "    \n",
    "    #create X and y\n",
    "    X_test_new=df[\"text\"]\n",
    "    y_test_new=df[\"fake\"]\n",
    " \n",
    "    #tokenize\n",
    "    X_test_token_new=tk.texts_to_sequences(X_test_new)\n",
    "    \n",
    "    #pad\n",
    "    X_test_pad_new=pad_sequences(X_test_token_new,  padding='pre', maxlen=max_len)\n",
    "    \n",
    "    #evaluate\n",
    "    report=model.evaluate(X_test_pad_new, y_test_new, return_dict=True)\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "21d3053e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#create test function for rnn with glove embedding\n",
    "def test_score_RNN_2(model, dataset_name):\n",
    "    \"\"\"\n",
    "    input a pipe (preprocessing and modeling)\n",
    "    output a classification report on the test set\n",
    "    \"\"\"\n",
    "    \n",
    "    #load data\n",
    "    df=dataset_name\n",
    "    \n",
    "    #apply preprocessing\n",
    "    #df['text'] = df.text.apply(preprocessing)\n",
    "    \n",
    "    #create X and y\n",
    "    X_test_new=df[\"text\"]\n",
    "    y_test_new=df[\"fake\"]\n",
    " \n",
    "    #tokenize\n",
    "    X_test_token_new = X_test_new.apply(word_tokenize)\n",
    "    \n",
    "    #embed\n",
    "    X_test_embed_new = X_test_token_new.apply(embed_sentence)\n",
    "    \n",
    "    #pad\n",
    "    X_test_pad_new=pad_sequences(X_test_embed_new,  padding='pre', maxlen=max_len)\n",
    "    \n",
    "    \n",
    "    #evaluate\n",
    "    report=model.evaluate(X_test_pad_new, y_test_new, return_dict=True)\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ffa440",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff09e479",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4160dae",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.7431192660550459,\n",
       "  'recall': 0.7074235807860262,\n",
       "  'f1-score': 0.7248322147651007,\n",
       "  'support': 687.0},\n",
       " '1': {'precision': 0.7305630026809652,\n",
       "  'recall': 0.7643758765778401,\n",
       "  'f1-score': 0.7470870459218644,\n",
       "  'support': 713.0},\n",
       " 'accuracy': 0.7364285714285714,\n",
       " 'macro avg': {'precision': 0.7368411343680055,\n",
       "  'recall': 0.7358997286819331,\n",
       "  'f1-score': 0.7359596303434826,\n",
       "  'support': 1400.0},\n",
       " 'weighted avg': {'precision': 0.7367245404938176,\n",
       "  'recall': 0.7364285714285714,\n",
       "  'f1-score': 0.736166282347081,\n",
       "  'support': 1400.0}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "classification_report(y_test, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbed34f2",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Naive Bayes tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f183761a",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.7111111111111111,\n",
       "  'recall': 0.8384279475982532,\n",
       "  'f1-score': 0.7695390781563126,\n",
       "  'support': 687.0},\n",
       " '1': {'precision': 0.811864406779661,\n",
       "  'recall': 0.6718092566619915,\n",
       "  'f1-score': 0.7352264006139677,\n",
       "  'support': 713.0},\n",
       " 'accuracy': 0.7535714285714286,\n",
       " 'macro avg': {'precision': 0.7614877589453861,\n",
       "  'recall': 0.7551186021301224,\n",
       "  'f1-score': 0.7523827393851401,\n",
       "  'support': 1400.0},\n",
       " 'weighted avg': {'precision': 0.7624233252623083,\n",
       "  'recall': 0.7535714285714286,\n",
       "  'f1-score': 0.7520641216651042,\n",
       "  'support': 1400.0}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2 = make_pipeline(TfidfVectorizer(max_features=300), MultinomialNB(alpha=0.1))\n",
    "pipe2.fit(X_train, y_train)\n",
    "y_pred = pipe2.predict(X_test)\n",
    "classification_report(y_test, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae38d4b8",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0831c69a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.749379652605459,\n",
       "  'recall': 0.8791848617176128,\n",
       "  'f1-score': 0.8091091761553918,\n",
       "  'support': 687.0},\n",
       " '1': {'precision': 0.8602693602693603,\n",
       "  'recall': 0.7166900420757363,\n",
       "  'f1-score': 0.7819433817903596,\n",
       "  'support': 713.0},\n",
       " 'accuracy': 0.7964285714285714,\n",
       " 'macro avg': {'precision': 0.8048245064374097,\n",
       "  'recall': 0.7979374518966745,\n",
       "  'f1-score': 0.7955262789728756,\n",
       "  'support': 1400.0},\n",
       " 'weighted avg': {'precision': 0.805854196580003,\n",
       "  'recall': 0.7964285714285714,\n",
       "  'f1-score': 0.7952740251680575,\n",
       "  'support': 1400.0}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe3 = make_pipeline(TfidfVectorizer(), SVC(kernel=\"rbf\"))\n",
    "pipe3.fit(X_train, y_train)\n",
    "y_pred = pipe3.predict(X_test)\n",
    "classification_report(y_test, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49a9f21",
   "metadata": {},
   "source": [
    "## SVM tuned 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "62e3f505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.7171464330413017,\n",
       "  'recall': 0.834061135371179,\n",
       "  'f1-score': 0.7711978465679677,\n",
       "  'support': 687.0},\n",
       " '1': {'precision': 0.8103161397670549,\n",
       "  'recall': 0.6830294530154277,\n",
       "  'f1-score': 0.7412480974124809,\n",
       "  'support': 713.0},\n",
       " 'accuracy': 0.7571428571428571,\n",
       " 'macro avg': {'precision': 0.7637312864041783,\n",
       "  'recall': 0.7585452941933033,\n",
       "  'f1-score': 0.7562229719902243,\n",
       "  'support': 1400.0},\n",
       " 'weighted avg': {'precision': 0.7645964336809175,\n",
       "  'recall': 0.7571428571428571,\n",
       "  'f1-score': 0.7559448671766377,\n",
       "  'support': 1400.0}}"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe4 = make_pipeline(TfidfVectorizer(max_features=300), SVC(kernel=\"rbf\"))\n",
    "pipe4.fit(X_train, y_train)\n",
    "y_pred = pipe4.predict(X_test)\n",
    "classification_report(y_test, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b11a3cf8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kathrin/.pyenv/versions/3.10.6/envs/fake_news/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kathrin/.pyenv/versions/3.10.6/envs/fake_news/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kathrin/.pyenv/versions/3.10.6/envs/fake_news/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 1.0,\n",
       "  'recall': 0.9157884171434307,\n",
       "  'f1-score': 0.9560433803112066,\n",
       "  'support': 9963.0},\n",
       " '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0.0},\n",
       " 'accuracy': 0.9157884171434307,\n",
       " 'macro avg': {'precision': 0.5,\n",
       "  'recall': 0.45789420857171537,\n",
       "  'f1-score': 0.4780216901556033,\n",
       "  'support': 9963.0},\n",
       " 'weighted avg': {'precision': 1.0,\n",
       "  'recall': 0.9157884171434307,\n",
       "  'f1-score': 0.9560433803112066,\n",
       "  'support': 9963.0}}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score(pipe4, guardian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "56d8c3d3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[152], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipe4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[79], line 16\u001b[0m, in \u001b[0;36mtest_score\u001b[0;34m(pipe, dataset_name)\u001b[0m\n\u001b[1;32m     14\u001b[0m y_test_new\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfake\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#predict the label\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m y_pred_new\u001b[38;5;241m=\u001b[39m\u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_new\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#make a classification report\u001b[39;00m\n\u001b[1;32m     18\u001b[0m report\u001b[38;5;241m=\u001b[39mclassification_report(y_test_new, y_pred_new, output_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/fake_news/lib/python3.10/site-packages/sklearn/pipeline.py:515\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    514\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[0;32m--> 515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpredict_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/fake_news/lib/python3.10/site-packages/sklearn/svm/_base.py:818\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    816\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 818\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/fake_news/lib/python3.10/site-packages/sklearn/svm/_base.py:433\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    431\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_for_predict(X)\n\u001b[1;32m    432\u001b[0m predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict\n\u001b[0;32m--> 433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/fake_news/lib/python3.10/site-packages/sklearn/svm/_base.py:479\u001b[0m, in \u001b[0;36mBaseLibSVM._sparse_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    475\u001b[0m kernel_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_kernels\u001b[38;5;241m.\u001b[39mindex(kernel)\n\u001b[1;32m    477\u001b[0m C \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m  \u001b[38;5;66;03m# C is not useful here\u001b[39;00m\n\u001b[0;32m--> 479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlibsvm_sparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibsvm_sparse_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport_vectors_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport_vectors_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport_vectors_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dual_coef_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_intercept_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mLIBSVM_IMPL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001b[39;49;00m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_class_weight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_n_support\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_probA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_probB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_score(pipe4, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "0d2fcffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.6935813109548651,\n",
       "  'recall': 0.9208069858476362,\n",
       "  'f1-score': 0.791203104786546,\n",
       "  'support': 9963.0},\n",
       " '1': {'precision': 0.8909919867366676,\n",
       "  'recall': 0.6140735098076557,\n",
       "  'f1-score': 0.7270574971815107,\n",
       "  'support': 10502.0},\n",
       " 'accuracy': 0.763400928414366,\n",
       " 'macro avg': {'precision': 0.7922866488457663,\n",
       "  'recall': 0.767440247827646,\n",
       "  'f1-score': 0.7591303009840283,\n",
       "  'support': 20465.0},\n",
       " 'weighted avg': {'precision': 0.7948863154533009,\n",
       "  'recall': 0.763400928414366,\n",
       "  'f1-score': 0.7582855787143211,\n",
       "  'support': 20465.0}}"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score(pipe4, guard_corp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eb3516",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## LSTM with Keras embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "62874bc7",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 70779 different words in your corpus\n"
     ]
    }
   ],
   "source": [
    "### Let's tokenize the vocabulary \n",
    "tk = Tokenizer(num_words=20000)\n",
    "tk.fit_on_texts(X_train)\n",
    "vocab_size = len(tk.word_index)\n",
    "print(f'There are {vocab_size} different words in your corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a654d2f9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "max_features = 20000  # Maximum number of words to get out of our data\n",
    "max_len = 300  # Maximum sequence length\n",
    "embedding_dim = 50  # Dimensionality of word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "68732af2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max index in training data: 19999\n",
      "Max index in test data: 19999\n"
     ]
    }
   ],
   "source": [
    "#tokenization\n",
    "X_train_token = tk.texts_to_sequences(X_train)\n",
    "X_test_token=tk.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad the inputs to a fixed length\n",
    "X_train_pad = pad_sequences(X_train_token,  padding='pre', maxlen=max_len)\n",
    "X_test_pad=pad_sequences(X_test_token,  padding='pre', maxlen=max_len)\n",
    "\n",
    "print(\"Max index in training data:\", np.max(X_train_pad))\n",
    "print(\"Max index in test data:\", np.max(X_test_pad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "090c89be",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 300, 50)           1000000   \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 16)                4288      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,004,305\n",
      "Trainable params: 1,004,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_dim, input_length=max_len))\n",
    "model.add(LSTM(16))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "metrics=['accuracy', 'Precision', 'Recall' ]\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=metrics)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f602967",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "44/44 [==============================] - 18s 242ms/step - loss: 0.6833 - accuracy: 0.5954 - precision: 0.6957 - recall: 0.3323 - val_loss: 0.6574 - val_accuracy: 0.6607 - val_precision: 0.6990 - val_recall: 0.5863\n",
      "Epoch 2/20\n",
      "44/44 [==============================] - 7s 168ms/step - loss: 0.5205 - accuracy: 0.7754 - precision: 0.7981 - recall: 0.7345 - val_loss: 0.5403 - val_accuracy: 0.7329 - val_precision: 0.8133 - val_recall: 0.6171\n",
      "Epoch 3/20\n",
      "44/44 [==============================] - 6s 126ms/step - loss: 0.3310 - accuracy: 0.8755 - precision: 0.8822 - recall: 0.8654 - val_loss: 0.5718 - val_accuracy: 0.7443 - val_precision: 0.7326 - val_recall: 0.7840\n",
      "Epoch 4/20\n",
      "44/44 [==============================] - 8s 190ms/step - loss: 0.2038 - accuracy: 0.9375 - precision: 0.9410 - recall: 0.9329 - val_loss: 0.6433 - val_accuracy: 0.7329 - val_precision: 0.7738 - val_recall: 0.6718\n",
      "Epoch 5/20\n",
      "44/44 [==============================] - 8s 191ms/step - loss: 0.1291 - accuracy: 0.9663 - precision: 0.9666 - recall: 0.9656 - val_loss: 0.7084 - val_accuracy: 0.7107 - val_precision: 0.6969 - val_recall: 0.7644\n",
      "Epoch 6/20\n",
      "44/44 [==============================] - 9s 210ms/step - loss: 0.0869 - accuracy: 0.9804 - precision: 0.9779 - recall: 0.9828 - val_loss: 0.8093 - val_accuracy: 0.7186 - val_precision: 0.7628 - val_recall: 0.6494\n",
      "Epoch 7/20\n",
      "44/44 [==============================] - 5s 118ms/step - loss: 0.0617 - accuracy: 0.9866 - precision: 0.9850 - recall: 0.9882 - val_loss: 0.8466 - val_accuracy: 0.7179 - val_precision: 0.7098 - val_recall: 0.7546\n",
      "Epoch 8/20\n",
      "44/44 [==============================] - 8s 172ms/step - loss: 0.0431 - accuracy: 0.9918 - precision: 0.9896 - recall: 0.9939 - val_loss: 0.9006 - val_accuracy: 0.7079 - val_precision: 0.7129 - val_recall: 0.7139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc64a730580>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Early Stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_recall',  # Stop when validation loss stops improving\n",
    "    patience=5,          # Wait for 3 epochs without improvement before stopping\n",
    "    mode=\"max\",\n",
    "    restore_best_weights=True  # Restore the best model weights after stopping\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_pad, y_train, batch_size=128, epochs=20, validation_data=(X_test_pad, y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "52c6cc7f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 1s 24ms/step - loss: 0.5718 - accuracy: 0.7443 - precision: 0.7326 - recall: 0.7840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.5717882513999939,\n",
       " 'accuracy': 0.7442857027053833,\n",
       " 'precision': 0.7326343655586243,\n",
       " 'recall': 0.7840112447738647}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate(X_test_pad, y_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1200d674",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 7s 22ms/step - loss: 0.6149 - accuracy: 0.6991 - precision: 0.0000e+00 - recall: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.6149290800094604,\n",
       " 'accuracy': 0.699086606502533,\n",
       " 'precision': 0.0,\n",
       " 'recall': 0.0}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score_RNN(model, guardian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "736497b4",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 [==============================] - 4s 13ms/step - loss: 0.9589 - accuracy: 0.4970 - precision: 1.0000 - recall: 0.4970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.9589491486549377,\n",
       " 'accuracy': 0.49704816937446594,\n",
       " 'precision': 1.0,\n",
       " 'recall': 0.49704816937446594}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score_RNN(model, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76417feb",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## LSTM with GloVe embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2c69b6c0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_wiki = gensim.downloader.load('glove-wiki-gigaword-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cffacd79",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "max_len = 300  # Maximum sequence length\n",
    "embedding_dim = 50  # Dimensionality of word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0e6513b7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Function to embed a sentence\n",
    "def embed_sentence(sentence, model=model_wiki, embedding_dim=50):\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in model:  # Directly check in model (no `.wv` needed)\n",
    "            embedded_sentence.append(model[word])  # Get vector\n",
    "    return np.array(embedded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3ff85cd4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#tokenization\n",
    "X_train_token = X_train.apply(word_tokenize)\n",
    "X_test_token=X_test.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c30a0667",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_embed = X_train_token.apply(embed_sentence)\n",
    "X_test_embed = X_test_token.apply(embed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "253eba41",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Pad the inputs to a fixed length\n",
    "X_train_pad = pad_sequences(X_train_embed,  padding='pre', maxlen=max_len)\n",
    "X_test_pad=pad_sequences(X_test_embed,  padding='pre', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fe613390",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 16)                4288      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,305\n",
      "Trainable params: 4,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "# No Embedding layer needed since inputs are already embedded (X_train_pad)\n",
    "model2.add(LSTM(16, input_shape=(300, 50)))  # Add LSTM layer with 16 units\n",
    "model2.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model\n",
    "metrics = ['accuracy', 'Precision', 'Recall']\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=metrics)\n",
    "\n",
    "# Check model summary\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4bce35b6",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "28/28 [==============================] - 6s 165ms/step - loss: 0.6942 - accuracy: 0.5180 - precision: 0.5141 - recall: 0.5755 - val_loss: 0.6868 - val_accuracy: 0.5686 - val_precision: 0.5782 - val_recall: 0.5652\n",
      "Epoch 2/20\n",
      "28/28 [==============================] - 5s 164ms/step - loss: 0.6823 - accuracy: 0.5704 - precision: 0.5624 - recall: 0.6161 - val_loss: 0.6770 - val_accuracy: 0.5900 - val_precision: 0.5951 - val_recall: 0.6101\n",
      "Epoch 3/20\n",
      "28/28 [==============================] - 6s 202ms/step - loss: 0.6697 - accuracy: 0.6002 - precision: 0.5951 - recall: 0.6150 - val_loss: 0.6636 - val_accuracy: 0.6029 - val_precision: 0.6149 - val_recall: 0.5891\n",
      "Epoch 4/20\n",
      "28/28 [==============================] - 5s 163ms/step - loss: 0.6497 - accuracy: 0.6261 - precision: 0.6175 - recall: 0.6534 - val_loss: 0.6503 - val_accuracy: 0.6214 - val_precision: 0.6060 - val_recall: 0.7335\n",
      "Epoch 5/20\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 0.6275 - accuracy: 0.6520 - precision: 0.6367 - recall: 0.7000 - val_loss: 0.6436 - val_accuracy: 0.6350 - val_precision: 0.6629 - val_recall: 0.5764\n",
      "Epoch 6/20\n",
      "28/28 [==============================] - 5s 195ms/step - loss: 0.6379 - accuracy: 0.6329 - precision: 0.6017 - recall: 0.7757 - val_loss: 0.6492 - val_accuracy: 0.6279 - val_precision: 0.6611 - val_recall: 0.5526\n",
      "Epoch 7/20\n",
      "28/28 [==============================] - 6s 199ms/step - loss: 0.6206 - accuracy: 0.6650 - precision: 0.6567 - recall: 0.6850 - val_loss: 0.6408 - val_accuracy: 0.6421 - val_precision: 0.6493 - val_recall: 0.6466\n",
      "Epoch 8/20\n",
      "28/28 [==============================] - 6s 203ms/step - loss: 0.6127 - accuracy: 0.6727 - precision: 0.6666 - recall: 0.6850 - val_loss: 0.6560 - val_accuracy: 0.6386 - val_precision: 0.7002 - val_recall: 0.5077\n",
      "Epoch 9/20\n",
      "28/28 [==============================] - 6s 197ms/step - loss: 0.6192 - accuracy: 0.6587 - precision: 0.7190 - recall: 0.5160 - val_loss: 0.6323 - val_accuracy: 0.6507 - val_precision: 0.6801 - val_recall: 0.5933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc6911d3610>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Early Stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_recall',  # Stop when validation loss stops improving\n",
    "    patience=5,          # Wait for 3 epochs without improvement before stopping\n",
    "    mode=\"max\",\n",
    "    restore_best_weights=True  # Restore the best model weights after stopping\n",
    ")\n",
    "# Train the model\n",
    "model2.fit(X_train_pad, y_train, batch_size=200, epochs=20, validation_data=(X_test_pad, y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "705b08bc",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 2s 35ms/step - loss: 0.6503 - accuracy: 0.6214 - precision: 0.6060 - recall: 0.7335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.6502742767333984,\n",
       " 'accuracy': 0.6214285492897034,\n",
       " 'precision': 0.6060255169868469,\n",
       " 'recall': 0.7335203289985657}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test_pad, y_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5b7629d4",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 16:47:01.764959: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 597780000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 5s 15ms/step - loss: 0.5927 - accuracy: 0.6563 - precision: 0.0000e+00 - recall: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.5927222371101379,\n",
       " 'accuracy': 0.6563284397125244,\n",
       " 'precision': 0.0,\n",
       " 'recall': 0.0}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score_RNN_2(model2, guardian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d7b3ee87",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1/329 [..............................] - ETA: 20s - loss: 0.6938 - accuracy: 0.6562 - precision: 1.0000 - recall: 0.6562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 16:47:36.283638: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 630120000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 [==============================] - 8s 24ms/step - loss: 0.6776 - accuracy: 0.6255 - precision: 1.0000 - recall: 0.6255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.6776471734046936,\n",
       " 'accuracy': 0.6254999041557312,\n",
       " 'precision': 1.0,\n",
       " 'recall': 0.6254999041557312}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score_RNN_2(model2, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c30349",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
